{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4398600,"sourceType":"datasetVersion","datasetId":2580326}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-18T18:59:50.761914Z","iopub.execute_input":"2024-07-18T18:59:50.762737Z","iopub.status.idle":"2024-07-18T18:59:51.159362Z","shell.execute_reply.started":"2024-07-18T18:59:50.762704Z","shell.execute_reply":"2024-07-18T18:59:51.158433Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/online-payment-fraud-detection/onlinefraud.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n\n# Load the dataset\ndataset_path = '/kaggle/input/online-payment-fraud-detection/onlinefraud.csv'\ndataset = pd.read_csv(dataset_path)\n\n# Display the first few rows of the dataset\nprint(dataset.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-18T18:59:58.834405Z","iopub.execute_input":"2024-07-18T18:59:58.835145Z","iopub.status.idle":"2024-07-18T19:00:17.005441Z","shell.execute_reply.started":"2024-07-18T18:59:58.835116Z","shell.execute_reply":"2024-07-18T19:00:17.004353Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n\n      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n0  M1979787155             0.0             0.0        0               0  \n1  M2044282225             0.0             0.0        0               0  \n2   C553264065             0.0             0.0        1               0  \n3    C38997010         21182.0             0.0        1               0  \n4  M1230701703             0.0             0.0        0               0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for missing values\nprint(dataset.isnull().sum())\n\n# If there were missing values, you could fill them like this:\n# dataset.fillna(method='ffill', inplace=True)\n\n# Feature Engineering\n# One-hot encoding for 'type'\ndataset = pd.get_dummies(dataset, columns=['type'], drop_first=True)\n\n# Creating additional features\ndataset['errorBalanceOrig'] = dataset['newbalanceOrig'] + dataset['amount'] - dataset['oldbalanceOrg']\ndataset['errorBalanceDest'] = dataset['oldbalanceDest'] + dataset['amount'] - dataset['newbalanceDest']\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:00:22.077648Z","iopub.execute_input":"2024-07-18T19:00:22.078301Z","iopub.status.idle":"2024-07-18T19:00:25.591302Z","shell.execute_reply.started":"2024-07-18T19:00:22.078270Z","shell.execute_reply":"2024-07-18T19:00:25.590476Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"step              0\ntype              0\namount            0\nnameOrig          0\noldbalanceOrg     0\nnewbalanceOrig    0\nnameDest          0\noldbalanceDest    0\nnewbalanceDest    0\nisFraud           0\nisFlaggedFraud    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Dropping unnecessary columns\ndataset.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n\n# Normalizing numerical features\nscaler = MinMaxScaler()\ndataset[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'errorBalanceOrig', 'errorBalanceDest']] = scaler.fit_transform(\n    dataset[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'errorBalanceOrig', 'errorBalanceDest']]\n)\n\n# Display the first few rows of the processed dataset\nprint(dataset.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:00:27.236516Z","iopub.execute_input":"2024-07-18T19:00:27.237364Z","iopub.status.idle":"2024-07-18T19:00:28.640545Z","shell.execute_reply.started":"2024-07-18T19:00:27.237333Z","shell.execute_reply":"2024-07-18T19:00:28.639631Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n0     1  0.000106       0.002855        0.003233        0.000000   \n1     1  0.000020       0.000357        0.000391        0.000000   \n2     1  0.000002       0.000003        0.000000        0.000000   \n3     1  0.000002       0.000003        0.000000        0.000059   \n4     1  0.000126       0.000697        0.000603        0.000000   \n\n   newbalanceDest  isFraud  isFlaggedFraud  type_CASH_OUT  type_DEBIT  \\\n0             0.0        0               0          False       False   \n1             0.0        0               0          False       False   \n2             0.0        1               0          False       False   \n3             0.0        1               0           True       False   \n4             0.0        0               0          False       False   \n\n   type_PAYMENT  type_TRANSFER  errorBalanceOrig  errorBalanceDest  \n0          True          False      1.081718e-10          0.852022  \n1          True          False      1.081718e-10          0.851933  \n2         False           True      1.081718e-10          0.851914  \n3         False          False      1.081718e-10          0.852152  \n4          True          False      1.081718e-10          0.852043  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Splitting the data into features and target\nX = dataset.drop(columns=['isFraud'])\ny = dataset['isFraud']\n\n# Split the data: 70% train, 15% validation, 15% test\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n\nprint(f'Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:00:32.349702Z","iopub.execute_input":"2024-07-18T19:00:32.350473Z","iopub.status.idle":"2024-07-18T19:00:37.878554Z","shell.execute_reply.started":"2024-07-18T19:00:32.350444Z","shell.execute_reply":"2024-07-18T19:00:37.877640Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training set: (4453834, 13), Validation set: (954393, 13), Test set: (954393, 13)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Decision Tree Model Training and Evaluation\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Make predictions\ny_val_pred_dt = dt_model.predict(X_val)\ny_val_pred_proba_dt = dt_model.predict_proba(X_val)[:, 1]\n\n# Evaluate the model\nprecision_dt = precision_score(y_val, y_val_pred_dt)\nrecall_dt = recall_score(y_val, y_val_pred_dt)\nf1_dt = f1_score(y_val, y_val_pred_dt)\nroc_auc_dt = roc_auc_score(y_val, y_val_pred_proba_dt)\n\nprint(f'Decision Tree - Precision: {precision_dt:.4f}, Recall: {recall_dt:.4f}, F1-Score: {f1_dt:.4f}, ROC-AUC: {roc_auc_dt:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:00:39.930071Z","iopub.execute_input":"2024-07-18T19:00:39.930907Z","iopub.status.idle":"2024-07-18T19:01:33.341592Z","shell.execute_reply.started":"2024-07-18T19:00:39.930876Z","shell.execute_reply":"2024-07-18T19:01:33.340631Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Decision Tree - Precision: 0.9935, Recall: 0.9878, F1-Score: 0.9906, ROC-AUC: 0.9939\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy = accuracy_score(y_val, y_val_pred_dt)\nprint(f'Accuracy on Validation Set: {accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:01:38.791886Z","iopub.execute_input":"2024-07-18T19:01:38.792320Z","iopub.status.idle":"2024-07-18T19:01:38.934325Z","shell.execute_reply.started":"2024-07-18T19:01:38.792289Z","shell.execute_reply":"2024-07-18T19:01:38.933265Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy on Validation Set: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Random Forest Model Training and Evaluation\n# rf_model = RandomForestClassifier(random_state=42)\n# rf_model.fit(X_train, y_train)\n\n# # Make predictions\n# y_val_pred_rf = rf_model.predict(X_val)\n# y_val_pred_proba_rf = rf_model.predict_proba(X_val)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-07-18T18:17:24.592371Z","iopub.execute_input":"2024-07-18T18:17:24.593340Z","iopub.status.idle":"2024-07-18T18:33:39.617091Z","shell.execute_reply.started":"2024-07-18T18:17:24.593308Z","shell.execute_reply":"2024-07-18T18:33:39.616315Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # Evaluate the model\n# precision_rf = precision_score(y_val, y_val_pred_rf)\n# recall_rf = recall_score(y_val, y_val_pred_rf)\n# f1_rf = f1_score(y_val, y_val_pred_rf)\n# roc_auc_rf = roc_auc_score(y_val, y_val_pred_proba_rf)\n\n# print(f'Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-Score: {f1_rf:.4f}, ROC-AUC: {roc_auc_rf:.4f}')\n","metadata":{},"execution_count":null,"outputs":[]}]}